## Benchmarking FRB Search Software

* Date: February 21, 2019 
* Time: 9:30 - 17:00
* Location: University of Amsterdam

### People involved
* Joeri van Leeuwen (ASTRON, Dwingeloo, the Netherlands)
* Liam Connor (University of Amsterdam, Amsterdam, the Netherlands)
* Alessio Sclocco (Netherlands eScience Center, Amsterdam, the Netherlands)
* Adriënne Mendrik (Netherlands eScience Center, Amsterdam, the Netherlands) 
* Annette Langedijk (SURF, Utrecht, the Netherlands) 
* [*Please add your name*]

### Workshop program
* Opening by Liam Connor (University of Amsterdam, Amsterdam, the Netherlands)
* Talk by Adriënne Mendrik (Netherlands eScience Center, Amsterdam, the Netherlands) “Introduction to Challenges and the EYRA Benchmark Platform” 
["Grand Challenges in Medical Image Analysis"](https://github.com/NLeSC/IEEE-eScience-Tutorial-Designing-Benchmarks/blob/master/Grand%20Challenges%20in%20Medical%20Image%20Analysis.pdf)
* Liam Connor (University of Amsterdam) “Introduction to the FRB Detection Benchmark Initiative”
* Coffee Break
* Brainstorm on the FRB Detection Benchmark:
  * Input: Filterbank (.fil) or other
  * Output: Text file
    * What should be in there? SN, dispersion, pulse width, arrival time, scattering measure, ...
    * How should it be structured?
  * Benchmark data: 
    * Different telescopes (what data can people contribute? How large?)
    * Simulation of the FRBs
  * What metrics should be used to rank the algorithms?
* Lunch Break
* Break-out sessions
  * Dockerize software
  * Design Benchmark (data, simulations, metrics, etc)
* Closing

Potential deliverables:
* Global benchmark design and an overview of existing data
* Some dockerized software packages

